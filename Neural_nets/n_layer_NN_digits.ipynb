{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataprocess(location):\n",
    "    df = pd.read_csv(location)\n",
    "    \n",
    "    df.drop_duplicates(inplace=True)    # inplace is for overwriting\n",
    "    \n",
    "    df = df.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\n",
    "    \n",
    "    df.Sex[df.Sex == 'male'] = 1\n",
    "    df.Sex[df.Sex == 'female'] = 0\n",
    "\n",
    "    df.Embarked[df.Embarked == 'S'] = 1\n",
    "    df.Embarked[df.Embarked == 'C'] = 0\n",
    "    df.Embarked[df.Embarked == 'Q'] = 2\n",
    "    \n",
    "    age = df['Age']\n",
    "    df['Age'] = (age - age.mean())/age.std()\n",
    "    df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "    fare = df['Fare']\n",
    "    df['Fare'] = (fare - fare.mean())/fare.std()\n",
    "    df['Fare'].fillna(df['Fare'].mean())\n",
    "\n",
    "    df.ffill(inplace = True) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train test sets\n",
    "train_loc = r\"C:\\Users\\varun\\Coding\\ML\\titanic\\train.csv\"\n",
    "df_train = Dataprocess(train_loc)\n",
    "X_train = np.array(df_train.drop(['Survived'],axis = 1))\n",
    "y_train = np.array(df_train['Survived'])\n",
    "\n",
    "test_loc = r\"C:\\Users\\varun\\Coding\\ML\\titanic\\test.csv\"\n",
    "df_test = Dataprocess(test_loc)\n",
    "X_test = np.array(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (891, 7)\n",
      "Y_train:  (891, 1)\n",
      "X_test:   (418, 7)\n",
      "[[ 3.          1.         -0.5300051  ...  0.         -0.50216314\n",
      "   1.        ]\n",
      " [ 1.          0.          0.57143041 ...  0.          0.78640362\n",
      "   0.        ]\n",
      " [ 3.          0.         -0.25464622 ...  0.         -0.48857985\n",
      "   1.        ]\n",
      " ...\n",
      " [ 3.          0.         -0.73652426 ...  2.         -0.1761643\n",
      "   1.        ]\n",
      " [ 1.          1.         -0.25464622 ...  0.         -0.04435613\n",
      "   0.        ]\n",
      " [ 3.          1.          0.1583921  ...  0.         -0.49210144\n",
      "   2.        ]]\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "print('X_train: ' ,(X_train.shape))\n",
    "print('Y_train: ' ,(y_train.shape))\n",
    "print('X_test:  ' ,(X_test.shape))\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z) :\n",
    "    Z = np.asarray(Z, dtype = np.float64)\n",
    "    return(1/(1+np.exp(-Z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLU(Z) :\n",
    "    return np.maximum(0,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layers):  \n",
    "    parameters = {}\n",
    "\n",
    "    for i in range(len(layers)-1) :\n",
    "        W = np.random.randn(layers[i],layers[i+1]) * 0.01\n",
    "        b = np.zeros((1,layers[i+1]))\n",
    "\n",
    "        parameters[\"W\"+str(i+1)] = W\n",
    "        parameters[\"b\"+str(i+1)] = b\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_derivatives(layers,parameters,cache) :\n",
    "    activation_diff = {}\n",
    "    for i in range(len(layers) - 1) :\n",
    "        a = np.where(activation_diff[\"A\"+str(len(layers))] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 8, 9, 9, 8, 7, 6])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,2,3,4,5,6,7,8,9,9,8,7,6,5,4,3,2,1])\n",
    "b = np.where(a>5)\n",
    "a[b[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(y,A_final):\n",
    "    cost =  -np.mean(np.multiply(y,np.log(A_final)) + np.multiply((1-y),np.log(1-A_final)))\n",
    "    cost = float(np.squeeze(cost))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, layers) :\n",
    "\n",
    "    cache  = {}\n",
    "    A = X\n",
    "    for i in range(len(layers) - 1) :\n",
    "        Z = np.dot(A,parameters[\"W\"+str(i+1)]) + parameters[\"b\"+str(i+1)]\n",
    "        A = reLU(Z).reshape(A.shape[0],parameters[\"b\"+str(i+1)].shape[1])\n",
    "        \n",
    "        cache[\"Z\"+str(i+1)] = Z\n",
    "        cache[\"A\"+str(i+1)] = A\n",
    "        print(\"Z,A shapes\",Z.shape,A.shape)\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(layers,cache,parameters,X,y,m,activation_diff):\n",
    "\n",
    "    grads = {}\n",
    "    \n",
    "    dZ = np.multiply((y - cache[pos])/(cache[pos]*(1-cache[pos])),activation_diff[pos])\n",
    "\n",
    "    dW = (1/m)*np.dot(cache[prev_pos].T,dZ)\n",
    "    db = (1/m)*np.sum(dZ,axis=0)\n",
    "\n",
    "    grads[\"W\"+str(pos)] = dW\n",
    "    grads[\"b\"+str(pos)] = db\n",
    "\n",
    "    for i in range(1,len(layers) - 1) :\n",
    "        pos = \"A\"+str(len(layers)-i-1)\n",
    "        prev_pos = \"A\"+str(len(layers)-i-2)\n",
    "\n",
    "        dZ = np.multiply(dZ,activation_diff[pos])\n",
    "\n",
    "        dW = (1/m)*np.dot(cache[prev_pos].T,dZ)\n",
    "        db = (1/m)*np.sum(dZ,axis=0)\n",
    "\n",
    "        grads[\"W\"+str(pos)] = dW\n",
    "        grads[\"b\"+str(pos)] = db\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(layers, parameters, grads, learning_rate):\n",
    "\n",
    "    for i in range(len(layers)):\n",
    "        W = parameters[\"W\"+str(i+1)] -learning_rate*grads[\"W\"+str(i+1)]\n",
    "        b = parameters[\"b\"+str(i+1)] -learning_rate*grads[\"b\"+str(i+1)]\n",
    "\n",
    "        parameters[\"W\"+str(i+1)] = W\n",
    "        parameters[\"b\"+str(i+1)] = b\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15488/3674730422.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitialize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "iterations = 1\n",
    "learning_rate = 0.03\n",
    "m = X_train.shape[0]\n",
    "layers = [7,4,1]\n",
    "\n",
    "parameters = initialize_parameters(layers)\n",
    "for i in range(len(layers) - 1):\n",
    "    print(\"W\",i,\" shape: \",parameters[\"W\"+str(i)].shape)\n",
    "    print(\"b\",i,\" shape: \",parameters[\"b\"+str(i)].shape) \n",
    "    \n",
    "for i in range(0, iterations) :\n",
    "    cache = forward_propagation(X_train,parameters,layers)\n",
    "\n",
    "    activation_diff = activation_derivatives(layers,parameters,cache)\n",
    "    grads = backward_propagation(layers,cache,parameters,X_train,y_train,m)\n",
    "    \n",
    "    parameters = update_parameters(layers, parameters, grads, learning_rate)\n",
    "    if i%1000 == 0:\n",
    "        print(\"Cost for\",i,\"iterations\",cost_function(y_train, cache[\"A2\"]))\n",
    "\n",
    "print(\"Final cost after\",i,\"iterations\",cost_function(y_train, cache[\"A2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward_propagation() missing 1 required positional argument: 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21688/3830472315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"A2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfinal\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfinal\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward_propagation() missing 1 required positional argument: 'layers'"
     ]
    }
   ],
   "source": [
    "result = forward_propagation(X_train,parameters)\n",
    "final = result[\"A2\"]\n",
    "final[final > 0.5] = 1\n",
    "final[final < 0.5] = 0\n",
    "\n",
    "print(np.mean(final == y_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = forward_propagation(X_test,parameters)\n",
    "final = result[\"A2\"]\n",
    "final[final > 0.55] = 1\n",
    "final[final < 0.55] = 0\n",
    "\n",
    "myvar = []\n",
    "for i in range(final.shape[0]) :\n",
    "    myvar.append([892+i,int(final[i][0])])\n",
    "\n",
    "df = pd.DataFrame(myvar , columns = [\"PassengerId\",\"Survived\"])\n",
    "df.to_csv(r'C:\\Users\\varun\\Coding\\ML\\titanic\\gender_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ccf9f24fb63ed59c236fd10a93cb8b545ca3a39e47263b99763c8981aafa253"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
